import os, subprocess, cv2, random, tempfile, shutil
from typing import Optional, List
from datetime import datetime
from moviepy import VideoFileClip, ImageClip, CompositeVideoClip, AudioFileClip
from moviepy.video.fx import Crop

which_ubuntu = 'RunPod'


def get_output_filename(prefix, input_path, output_ext=".mp4"):
    """
    Generate output filename based on prefix and input path.
    
    Args:
        prefix: String prefix for the output filename
        input_path: Path to the input file
        output_ext: Extension for the output file (default: .mp4)
    
    Returns:
        Generated output filename
    """
    # Get the base name without extension
    base_name = os.path.splitext(os.path.basename(input_path))[0]
    
    # Create timestamp for uniqueness
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Combine prefix, base name, timestamp, and extension
    output_filename = f"{prefix}_{base_name}_{timestamp}{output_ext}"
    
    # Clean up any spaces or special characters
    output_filename = output_filename.replace(" ", "_").replace("(", "").replace(")", "")
    
    return output_filename


def get_local_font(language='chinese'):
    """
    æ ¹æ®è¿è¡Œç¯å¢ƒå’Œè¯­è¨€è¿”å›åˆé€‚çš„å­—ä½“åç§°
    
    Args:
        language (str): è¯­è¨€ç±»å‹ï¼Œ'chinese'ï¼ˆé»˜è®¤ï¼‰æˆ– 'english'
    
    Returns:
        str: å­—ä½“åç§°æˆ–å­—ä½“æ–‡ä»¶è·¯å¾„
    """
    import subprocess
    if language.lower() == 'english':
        # è‹±æ–‡ä½¿ç”¨Ubuntuå­—ä½“
        font_name = "Ubuntu"
    else:
        # ä¸­æ–‡ä¼˜å…ˆä½¿ç”¨éœé¹œæ–‡æ¥· Bold
        # æ‰€æœ‰ç³»ç»Ÿéƒ½ä¼˜å…ˆæ£€æŸ¥éœé¹œæ–‡æ¥·
        if which_ubuntu in ['TB', 'AWS', 'RunPod']:
            # Linuxç³»ç»Ÿ - å…ˆæ£€æŸ¥ç³»ç»Ÿæ˜¯å¦å®‰è£…äº†éœé¹œæ–‡æ¥·
            
            try:
                result = subprocess.run(['fc-list', ':family'], capture_output=True, text=True)
                if 'LXGW WenKai' in result.stdout:
                    # ç³»ç»Ÿå·²å®‰è£…ï¼Œè¿”å›å­—ä½“åç§°ï¼ˆä¸æ˜¯è·¯å¾„ï¼‰
                    return "LXGW WenKai Bold"
            except:
                pass
            
            # æ£€æŸ¥å­—ä½“æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            font_paths = [
                # æœ€ä¼˜å…ˆï¼šéœé¹œæ–‡æ¥· Bold
                "/usr/share/fonts/truetype/lxgw/LXGWWenKai-Bold.ttf",
                "/usr/local/share/fonts/LXGWWenKai-Bold.ttf",
                "/home/ubuntu/.local/share/fonts/LXGWWenKai-Bold.ttf",
                # å¤‡é€‰ï¼šæ€æºé»‘ä½“
                "/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc",
                "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
                "/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc",
                "/usr/share/fonts/truetype/wqy/wqy-microhei.ttc"
            ]
            for path in font_paths:
                if os.path.exists(path):
                    # å¦‚æœæ˜¯éœé¹œæ–‡æ¥·ï¼Œè¿”å›å­—ä½“åç§°è€Œä¸æ˜¯è·¯å¾„
                    if 'lxgw' in path.lower() or 'LXGWWenKai' in path:
                        return "LXGW WenKai Bold"
                    else:
                        # å…¶ä»–å­—ä½“è¿”å›è·¯å¾„
                        return path
            # å¦‚æœæ²¡æ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œè¿”å›Ubuntuä½œä¸ºåå¤‡
            font_name = "Ubuntu"
        else:
            # Macç³»ç»Ÿ - ä¹Ÿä¼˜å…ˆä½¿ç”¨éœé¹œæ–‡æ¥·
            # å…ˆæ£€æŸ¥ç³»ç»Ÿæ˜¯å¦å®‰è£…äº†éœé¹œæ–‡æ¥·
            try:
                result = subprocess.run(['fc-list', ':family'], capture_output=True, text=True)
                if 'LXGW WenKai' in result.stdout or 'éœé¹œæ–‡æ¥·' in result.stdout:
                    # ç³»ç»Ÿå·²å®‰è£…ï¼Œç›´æ¥ä½¿ç”¨å­—ä½“åç§°
                    font_name = "LXGW WenKai"
                    return font_name
            except:
                pass
            
            # å¦‚æœç³»ç»Ÿæ²¡æœ‰å®‰è£…ï¼Œæ£€æŸ¥æœ¬åœ°å­—ä½“æ–‡ä»¶
            mac_font_paths = [
                "/Library/Fonts/LXGWWenKai-Bold.ttf",
                os.path.expanduser("~/Library/Fonts/LXGWWenKai-Bold.ttf")
            ]
            
            for path in mac_font_paths:
                if os.path.exists(path):
                    # å¦‚æœæ˜¯ç³»ç»Ÿå­—ä½“ç›®å½•ï¼Œè¿”å›å­—ä½“åç§°è€Œä¸æ˜¯è·¯å¾„
                    if path.startswith("/Library/Fonts/") or path.startswith(os.path.expanduser("~/Library/Fonts/")):
                        font_name = "LXGW WenKai"
                        return font_name
                    else:
                        # é¡¹ç›®å†…çš„å­—ä½“æ–‡ä»¶ï¼Œè¿”å›è·¯å¾„
                        return path
            
            # å¦‚æœæ²¡æ‰¾åˆ°éœé¹œæ–‡æ¥·ï¼Œä½¿ç”¨é»˜è®¤çš„æ€æºé»‘ä½“
            font_name = "Noto Sans CJK SC"
    
    return font_name


EFFECTS = ["random", "zoom_in", "zoom_out", "pan_left", "pan_right"]

class AfterEffectsProcess:
    def __init__(self, output_folder, logger=None):
        self.output_folder = output_folder
        self.logger = logger

    def process_file(self, input_path=None, parameters=None, progress_callback=None, **kwargs):
        # Support both old and new calling methods
        if input_path and parameters:
            # Old method: backward compatibility
            skip_existed = parameters.get("skip_existed", True)
            effect = parameters.get("effect", "random")
            effects = parameters.get("effects", None)
            watermark_path = parameters.get("watermark_path", None)
            input_video = input_path
            input_image = None
            input_audio = None
        else:
            # New method: use **kwargs
            skip_existed = kwargs.get("skip_existed", True)
            effect = kwargs.get("effect", "random")
            effects = kwargs.get("effects", None)
            watermark_path = kwargs.get("watermark_path", None)
            input_video = kwargs.get("input_video", None)
            input_image = kwargs.get("input_image", None)
            input_audio = kwargs.get("input_audio", None)
            progress_callback = kwargs.get("progress_callback", progress_callback)
        
        # Input validation logic
        if input_video and os.path.exists(input_video):
            # Priority 1: Process existing video file
            if progress_callback:
                progress_callback(f"Processing video: {os.path.basename(input_video)}")
            source_path = input_video
            
        elif input_image and input_audio and os.path.exists(input_image) and os.path.exists(input_audio):
            # Priority 2: Create video from image + audio
            if progress_callback:
                progress_callback(f"Creating video from image and audio")
            source_path = self._create_video_from_image_audio(input_image, input_audio, progress_callback)
            if not source_path:
                return None
                
        else:
            # Error: Invalid input combination
            if progress_callback:
                progress_callback("Error: Must provide either input_video OR both input_image and input_audio")
            return None
        
        # Generate output path
        if input_path:
            output_name = get_output_filename("After Effects", input_path, output_ext=".mp4")
        else:
            base_name = os.path.basename(input_video) if input_video else f"{os.path.basename(input_image)}_with_audio"
            output_name = get_output_filename("After Effects", base_name, output_ext=".mp4")
        
        output_path = os.path.join(self.output_folder, output_name)
        if skip_existed and os.path.exists(output_path):
            return output_path
        try:
            clip = VideoFileClip(source_path)
            
            # Smart effect selection logic
            if effects and isinstance(effects, list) and len(effects) > 0:
                # Priority 1: Random selection from provided effects list
                chosen_effect = random.choice(effects)
                # ç§»é™¤å†—ä½™çš„ç‰¹æ•ˆé€‰æ‹©æ—¥å¿—
                # if progress_callback:
                #     progress_callback(f"Selected '{chosen_effect}' from effects list: {effects}")
            elif effect and effect != "random":
                # Priority 2: Use specified single effect
                chosen_effect = effect
            else:
                # Priority 3: Random from all available effects
                chosen_effect = random.choice([e for e in EFFECTS if e != "random"])
            # ç§»é™¤å†—ä½™çš„ç‰¹æ•ˆåº”ç”¨æ—¥å¿—
            # if progress_callback:
            #     progress_callback(f"Applying effect '{chosen_effect}' to {os.path.basename(source_path)}")
            temp_out_path = None
            original_audio = clip.audio  # Preserve original audio
            
            if chosen_effect in ("zoom_in", "zoom_out"):
                with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as temp_out:
                    temp_out_path = temp_out.name
                self._opencv_smooth_zoom(
                    source_path,
                    temp_out_path,
                    chosen_effect,
                    fps=int(getattr(clip, 'fps', 30) or 30),
                    w=clip.w,
                    h=clip.h,
                    progress_callback=progress_callback
                )
                # Load the video-only clip and restore audio
                clip = VideoFileClip(temp_out_path)
                if original_audio:
                    clip = clip.with_audio(original_audio)
                    # if progress_callback:  # æ¸…ç†å†—ä½™æ—¥å¿—
                    #     progress_callback("Audio restored from original video")
                        
            elif chosen_effect in ("pan_left", "pan_right"):
                with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as temp_out:
                    temp_out_path = temp_out.name
                self._opencv_smooth_pan(
                    source_path,
                    temp_out_path,
                    chosen_effect,
                    fps=int(getattr(clip, 'fps', 30) or 30),
                    w=clip.w,
                    h=clip.h,
                    progress_callback=progress_callback
                )
                # Load the video-only clip and restore audio
                clip = VideoFileClip(temp_out_path)
                if original_audio:
                    clip = clip.with_audio(original_audio)
                    # if progress_callback:  # æ¸…ç†å†—ä½™æ—¥å¿—
                    #     progress_callback("Audio restored from original video")
            w, h = clip.size
            
            # Auto-detect orientation and set appropriate aspect ratio
            if w > h:
                # Landscape: use 16:9 aspect ratio
                aspect = 16 / 9
                # ç§»é™¤å†—ä½™çš„æ ¼å¼æ£€æµ‹æ—¥å¿—
                # if progress_callback:
                #     progress_callback(f"Detected landscape format ({w}x{h}), using 16:9 aspect ratio")
            else:
                # Portrait: use 9:16 aspect ratio
                aspect = 9 / 16
                if progress_callback:
                    progress_callback(f"Detected portrait format ({w}x{h}), using 9:16 aspect ratio")
            
            effects = []
            current_aspect = w / h
            
            if abs(current_aspect - aspect) > 0.01:  # Only crop if aspect ratios differ significantly
                if current_aspect > aspect:
                    # Video is wider than target aspect ratio - crop horizontally
                    new_w = int(h * aspect)
                    x1 = (w - new_w) // 2
                    x2 = x1 + new_w
                    effects.append(Crop(x1=x1, y1=0, x2=x2, y2=h))
                    if progress_callback:
                        progress_callback(f"Cropping width from {w} to {new_w} pixels")
                elif current_aspect < aspect:
                    # Video is taller than target aspect ratio - crop vertically
                    new_h = int(w / aspect)
                    y1 = (h - new_h) // 2
                    y2 = y1 + new_h
                    effects.append(Crop(x1=0, y1=y1, x2=w, y2=y2))
                    if progress_callback:
                        progress_callback(f"Cropping height from {h} to {new_h} pixels")
            else:
                # ç§»é™¤å†—ä½™çš„aspect ratioæ—¥å¿—
                # if progress_callback:
                #     progress_callback(f"Video already has correct aspect ratio ({current_aspect:.3f}), no cropping needed")
                pass  # éœ€è¦passè¯­å¥æ¥æ»¡è¶³Pythonè¯­æ³•è¦æ±‚
            if effects:
                clip = clip.with_effects(effects)
            
            # Add watermark if provided
            if watermark_path and os.path.exists(watermark_path):
                if progress_callback:
                    progress_callback(f"Adding watermark: {os.path.basename(watermark_path)}")
                
                # Create watermark clip with same duration as video
                watermark_clip = ImageClip(watermark_path).with_duration(clip.duration)
                # Position watermark at top-left corner (10, 10) like in the original function
                watermark_clip = watermark_clip.with_position((10, 10))
                
                # Composite video with watermark
                clip = CompositeVideoClip([clip, watermark_clip])
                
                if progress_callback:
                    progress_callback("Watermark added successfully")
            
            # å†™å…¥è§†é¢‘æ–‡ä»¶ï¼Œç¡®ä¿éŸ³é¢‘ä¸º48kHz
            clip.write_videofile(output_path, 
                                codec='libx264', 
                                audio_codec='aac', 
                                audio_fps=48000,  # 48kHzé‡‡æ ·ç‡
                                audio_bitrate='128k',
                                threads=2, 
                                logger=None)
            
            # Clean up clips and audio
            if original_audio:
                original_audio.close()
            clip.close()
            if temp_out_path and os.path.exists(temp_out_path):
                os.remove(temp_out_path)
            return output_path
        except Exception as e:
            if progress_callback:
                progress_callback(f"Error processing {os.path.basename(source_path)}: {e}")
            return None

    def _create_video_from_image_audio(self, input_image, input_audio, progress_callback=None):
        """
        Create a video from image and audio files
        
        Args:
            input_image: Path to image file
            input_audio: Path to audio file
            progress_callback: Optional callback function
            
        Returns:
            Path to created video file or None if failed
        """
        try:
            # if progress_callback:  # æ¸…ç†å†—ä½™æ—¥å¿—
            #     progress_callback(f"Loading image: {os.path.basename(input_image)}")
            
            # Load audio to get duration
            audio_clip = AudioFileClip(input_audio)
            # å¼ºåˆ¶é‡é‡‡æ ·åˆ°48kHzä»¥ç¬¦åˆYouTubeæ ‡å‡†
            if audio_clip.fps != 48000:
                # if progress_callback:  # æ¸…ç†å†—ä½™æ—¥å¿—
                #     progress_callback(f"Resampling audio from {audio_clip.fps}Hz to 48000Hz...")
                audio_clip = audio_clip.with_fps(48000)
            audio_duration = audio_clip.duration
            
            # if progress_callback:  # æ¸…ç†å†—ä½™æ—¥å¿—
            #     progress_callback(f"Audio duration: {audio_duration:.2f} seconds")
            
            # Create video clip from image with audio duration
            image_clip = ImageClip(input_image).with_duration(audio_duration)
            image_clip = image_clip.with_fps(30)  # Set FPS for smooth playback
            
            # Apply smart cropping to maintain aspect ratio without distortion
            image_clip = self._apply_smart_cropping(image_clip, progress_callback)
            
            # Add audio to video
            video_clip = image_clip.with_audio(audio_clip)
            
            # Create temporary video file
            temp_video = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False)
            temp_video_path = temp_video.name
            temp_video.close()
            
            if progress_callback:
                progress_callback("Creating video from image and audio...")
            
            # ğŸ¯ GPUç¼–ç å™¨æ£€æµ‹å’Œé€‰æ‹© - ä½¿ç”¨ç›´æ¥FFmpegè°ƒç”¨è€ŒéMoviePy
            if progress_callback:
                progress_callback("Detecting optimal video encoder (GPU/CPU)...")
            
            # æµ‹è¯•h264_nvencç¼–ç å™¨æ˜¯å¦å¯ç”¨
            encoder_test_cmd = ['ffmpeg', '-hide_banner', '-f', 'lavfi', '-i', 'nullsrc=s=256x256:d=0.1', '-c:v', 'h264_nvenc', '-f', 'null', '-']
            use_gpu_encoding = False
            try:
                test_result = subprocess.run(encoder_test_cmd, capture_output=True, text=True, timeout=10)
                if test_result.returncode == 0:
                    use_gpu_encoding = True
                    if progress_callback:
                        progress_callback("âœ… GPU encoder available - will use direct FFmpeg with h264_nvenc")
                else:
                    if progress_callback:
                        progress_callback("ğŸ–¥ï¸  GPU encoder not available - using MoviePy with libx264")
            except Exception as e:
                if progress_callback:
                    progress_callback(f"âš ï¸  GPU test failed - using MoviePy with libx264: {str(e)[:100]}")
            
            if use_gpu_encoding:
                # ä½¿ç”¨ç›´æ¥FFmpegè°ƒç”¨è¿›è¡ŒGPUç¼–ç 
                if progress_callback:
                    progress_callback("Creating video with direct FFmpeg GPU encoding...")
                
                # æ„å»ºFFmpegå‘½ä»¤
                ffmpeg_cmd = [
                    'ffmpeg', '-y', '-loglevel', 'quiet',
                    '-loop', '1', '-i', input_image,
                    '-i', input_audio,
                    '-c:v', 'h264_nvenc',           # GPUç¼–ç å™¨
                    '-preset', 'p4',                # NVENCé¢„è®¾
                    '-cq:v', '19',                  # è´¨é‡å› å­
                    '-c:a', 'aac',                  # éŸ³é¢‘ç¼–ç å™¨
                    '-af', 'aresample=48000',       # éŸ³é¢‘é‡é‡‡æ ·æ»¤é•œ
                    '-ar', '48000',                 # 48kHzé‡‡æ ·ç‡
                    '-ac', '2',                     # ç«‹ä½“å£°
                    '-b:a', '128k',                 # éŸ³é¢‘æ¯”ç‰¹ç‡
                    '-pix_fmt', 'yuv420p',          # åƒç´ æ ¼å¼
                    '-r', '30',                     # å¸§ç‡
                    '-shortest',                    # ä»¥æœ€çŸ­æµä¸ºå‡†
                    '-vsync', 'cfr',                # å›ºå®šå¸§ç‡
                    temp_video_path
                ]
                
                result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True)
                if result.returncode != 0:
                    raise Exception(f"FFmpeg GPU encoding failed: {result.stderr}")
                    
                if progress_callback:
                    progress_callback("âœ… Direct FFmpeg GPU encoding completed")
            else:
                # å›é€€åˆ°MoviePyçš„CPUç¼–ç 
                if progress_callback:
                    progress_callback("Using MoviePy CPU encoding fallback...")
                
                # MoviePy write_videofile with compatible parameters
                write_params = {
                    'codec': 'libx264',
                    'audio_codec': 'aac',
                    'audio_bitrate': '128k',
                    'audio_fps': 48000,  # 48kHzé‡‡æ ·ç‡ï¼ˆYouTubeæ ‡å‡†ï¼‰
                    'preset': 'medium',
                    'threads': 2,
                    'logger': None
                }
                
                # Try with crf parameter, fallback without it if not supported
                try:
                    video_clip.write_videofile(
                        temp_video_path,
                        crf=23,
                        **write_params
                    )
                except TypeError:
                    # Older MoviePy version without crf support
                    video_clip.write_videofile(
                        temp_video_path,
                        **write_params
                    )
            
            # Clean up clips
            audio_clip.close()
            image_clip.close()
            video_clip.close()
            
            if progress_callback:
                progress_callback("Video created successfully from image and audio")
            
            return temp_video_path
            
        except Exception as e:
            if progress_callback:
                progress_callback(f"Error creating video from image and audio: {e}")
            return None

    def _apply_smart_cropping(self, clip, progress_callback=None):
        """
        Apply smart cropping to maintain proper aspect ratio without distortion
        
        Args:
            clip: VideoClip to crop
            progress_callback: Optional callback function
            
        Returns:
            Cropped clip with proper aspect ratio
        """
        try:
            w, h = clip.size
            current_aspect = w / h
            
            # Determine target aspect ratio based on orientation
            if w > h:
                # Landscape: use 16:9 aspect ratio
                target_aspect = 16 / 9
                orientation = "landscape"
            else:
                # Portrait: use 9:16 aspect ratio
                target_aspect = 9 / 16
                orientation = "portrait"
            
            if progress_callback:
                progress_callback(f"Input: {w}x{h} ({orientation}, aspect: {current_aspect:.3f})")
                progress_callback(f"Target aspect: {target_aspect:.3f}")
            
            # Check if cropping is needed
            if abs(current_aspect - target_aspect) <= 0.01:
                if progress_callback:
                    progress_callback("No cropping needed - aspect ratio already correct")
                return clip
            
            # Calculate crop dimensions (center-based cropping)
            if current_aspect > target_aspect:
                # Image is wider than target - crop width (left and right)
                new_w = int(h * target_aspect)
                new_h = h
                x_offset = (w - new_w) // 2  # Center horizontally
                y_offset = 0
                if progress_callback:
                    progress_callback(f"Cropping width: {w} â†’ {new_w} (removing {x_offset} pixels from each side)")
            else:
                # Image is taller than target - crop height (top and bottom)
                new_w = w
                new_h = int(w / target_aspect)
                x_offset = 0
                y_offset = (h - new_h) // 2  # Center vertically
                if progress_callback:
                    progress_callback(f"Cropping height: {h} â†’ {new_h} (removing {y_offset} pixels from top and bottom)")
            
            # Apply center-based cropping
            cropped_clip = clip.with_effects([
                Crop(x1=x_offset, y1=y_offset, x2=x_offset + new_w, y2=y_offset + new_h)
            ])
            
            if progress_callback:
                progress_callback(f"Smart cropping applied: {new_w}x{new_h} (aspect: {new_w/new_h:.3f})")
            
            return cropped_clip
            
        except Exception as e:
            if progress_callback:
                progress_callback(f"Error in smart cropping: {e}")
            return clip  # Return original clip if cropping fails

    @staticmethod
    def _opencv_smooth_zoom(input_path, output_path, effect, fps, w, h, progress_callback=None):
        """
        Generate a smooth zoom in/out video using OpenCV per-frame affine transform.
        The center remains fixed, and zoom is linearly interpolated from 1.0 to 1.1 (in) or 1.1 to 1.0 (out).
        """
        cap = cv2.VideoCapture(input_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        in_fps = cap.get(cv2.CAP_PROP_FPS) or fps
        if total_frames <= 1:
            total_frames = 2
        fourcc = cv2.VideoWriter_fourcc(*"mp4v")
        writer = cv2.VideoWriter(output_path, fourcc, fps, (w, h))
        if effect == "zoom_in":
            start_zoom, end_zoom = 1.0, 1.1
        else:
            start_zoom, end_zoom = 1.1, 1.0
        for i in range(total_frames):
            ret, frame = cap.read()
            if not ret:
                break
            alpha = i / (total_frames - 1)
            zoom = start_zoom + alpha * (end_zoom - start_zoom)
            # Build affine transform to keep center fixed
            center = (w / 2, h / 2)
            M = cv2.getRotationMatrix2D(center, 0, zoom)
            frame_zoomed = cv2.warpAffine(frame, M, (w, h), flags=cv2.INTER_LANCZOS4)
            writer.write(frame_zoomed)
            # ç§»é™¤å†—ä½™çš„zoomè¿›åº¦æ—¥å¿—ï¼Œå·²ç»å¾ˆç¨³å®šäº†
            # if progress_callback and (i == 0 or i == total_frames // 2 or i == total_frames - 1):
            #     progress_callback(f"Zoom progress: {int((i+1) * 100 / total_frames)}%")
        cap.release()
        writer.release()

    @staticmethod
    def _opencv_smooth_pan(input_path, output_path, effect, fps, w, h, progress_callback=None):
        """
        Generate a smooth pan left/right video using OpenCV per-frame crop.
        For pan left: first frame's right edge aligns with output right, last frame is centered.
        For pan right: first frame's left edge aligns with output left, last frame is centered.
        Crop window matches 9:16 aspect ratio.
        """
        # Auto-detect orientation and set appropriate aspect ratio
        if w > h:
            # Landscape: use 16:9 aspect ratio
            aspect = 16 / 9
        else:
            # Portrait: use 9:16 aspect ratio
            aspect = 9 / 16
            
        if w / h > aspect:
            crop_w = int(h * aspect)
            crop_h = h
        else:
            crop_w = w
            crop_h = int(w / aspect)
        center_x = (w - crop_w) // 2
        if effect == "pan_left":
            start_x = w - crop_w  # right edge aligns
            end_x = center_x      # center
        else:  # pan_right
            start_x = 0          # left edge aligns
            end_x = center_x     # center
        cap = cv2.VideoCapture(input_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        in_fps = cap.get(cv2.CAP_PROP_FPS) or fps
        if total_frames <= 1:
            total_frames = 2
        fourcc = cv2.VideoWriter_fourcc(*"mp4v")
        writer = cv2.VideoWriter(output_path, fourcc, fps, (crop_w, crop_h))
        for i in range(total_frames):
            ret, frame = cap.read()
            if not ret:
                break
            alpha = i / (total_frames - 1)
            x = int(round(start_x + (end_x - start_x) * alpha))
            y = 0 if crop_h == h else (h - crop_h) // 2
            # Crop window
            crop = frame[y:y+crop_h, x:x+crop_w]
            # If needed, resize to output size (shouldn't be needed, but for safety)
            if crop.shape[1] != crop_w or crop.shape[0] != crop_h:
                crop = cv2.resize(crop, (crop_w, crop_h), interpolation=cv2.INTER_LANCZOS4)
            writer.write(crop)
            # åªåœ¨å¼€å§‹ã€ä¸­é—´å’Œç»“æŸæ—¶æ‰“å°è¿›åº¦
            if progress_callback and (i == 0 or i == total_frames // 2 or i == total_frames - 1):
                progress_callback(f"Pan progress: {int((i+1) * 100 / total_frames)}%")
        cap.release()
        writer.release() 


def merge_audio_image_to_video_with_effects(input_mp3, input_image, output_video=None, effects: list = ["zoom_in", "zoom_out"], watermark_path=None) -> tuple[bool, str]:
    """
    Merges an MP3 audio file and a static image into a video file with effects and watermark.
    Uses the tested AfterEffectsProcess class for all processing.
    
    Args:
        input_mp3 (str): Path to the input MP3 file.
        input_image (str): Path to the input image file (e.g., JPG, PNG).
        output_video (str): Path for the output video file (e.g., MP4).
        effects (list, optional): List of effects to randomly choose from. Default: ["zoom_in", "zoom_out"]
        watermark_path (str, optional): Path to watermark image file.

    Returns:
        tuple[bool, str]: (success_status, output_path_or_error_message)
    """
    try:
        # é¦–å…ˆå°†æ‰€æœ‰è·¯å¾„è½¬æ¢ä¸ºç»å¯¹è·¯å¾„
        input_mp3 = os.path.abspath(input_mp3)
        input_image = os.path.abspath(input_image)
        
        if not output_video: output_video = input_mp3.replace('.mp3', '.mp4')
        output_video = os.path.abspath(output_video)
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_dir = os.path.dirname(output_video)
        if not os.path.exists(output_dir): os.makedirs(output_dir, exist_ok=True)
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨è¾“å‡ºæ–‡ä»¶
        if os.path.isfile(output_video): return True, output_video

        # Check if input files exist
        if not os.path.exists(input_mp3): return False, f"Error: Input audio file not found: {input_mp3}"
        if not os.path.exists(input_image): return False, f"Error: Input image file not found: {input_image}"
        
        # Default effects if not provided or None (but preserve empty list)
        if effects is None: 
            effects = ["zoom_in", "zoom_out"]
        
        # Create temporary output directory for AfterEffectsProcess
        temp_output_dir = os.path.dirname(output_video)
        processor = AfterEffectsProcess(output_folder=temp_output_dir)
        
        # Process with effects using our tested class
        result = processor.process_file(
            input_image=input_image,
            input_audio=input_mp3,
            effects=effects,
            watermark_path=watermark_path,
            skip_existed=False,  # Always process for this function
            progress_callback=print  # ä½¿ç”¨printå‡½æ•°ä½œä¸ºprogress_callbackä»¥æ˜¾ç¤ºGPU/CPUä¿¡æ¯
        )
        
        if result: # Move result to expected output path if different
            if result != output_video: shutil.move(result, output_video)
            return True, output_video
        else: return False, "Error: Video processing failed"
            
    except Exception as e: return False, f"Error creating video: {str(e)}"



def add_subtitles_to_video(input_video_path: str, subtitle_path: str, output_video_path: str = None, font_size: int = None, outline_color: str = "&H00000000", background_box: bool = True, background_opacity: float = 0.5, language: str = 'english', force_redo = False) -> bool:
    try:
        if not os.path.exists(input_video_path): return print(f"Input video does not exist at {input_video_path}")
        if not os.path.exists(subtitle_path): return print(f"Subtitle file does not exist at {subtitle_path}")
        if os.path.isfile(output_video_path):
            if not force_redo: return print(f"Output video already exists at {output_video_path}")
            else: os.remove(output_video_path)
        
        # è·å–å­—ä½“ä¿¡æ¯
        font_info = get_local_font(language)
        font_dir = ""
        font_name = font_info
        
        # å¦‚æœè¿”å›çš„æ˜¯æ–‡ä»¶è·¯å¾„ï¼Œæå–å­—ä½“ç›®å½•å’Œå­—ä½“åç§°
        if isinstance(font_info, str) and os.path.exists(font_info) and font_info.endswith('.ttf'):
            font_dir = os.path.dirname(font_info)
            font_name = os.path.basename(font_info).replace('.ttf', '')
        elif isinstance(font_info, str) and '/' not in font_info:
            # å¦‚æœæ˜¯å­—ä½“åç§°ï¼ˆå¦‚ "Ubuntu"ï¼‰ï¼Œç›´æ¥ä½¿ç”¨
            font_name = font_info
        
        # è·å–è§†é¢‘ä¿¡æ¯
        video_info = {}
        try:
            cmd = f'ffprobe -v error -select_streams v:0 -show_entries stream=width,height -of csv=p=0:s=x "{input_video_path}"'
            result = subprocess.check_output(cmd, shell=True).decode('utf-8').strip()
            if result and 'x' in result:
                video_width, video_height = map(int, result.split('x'))
                video_info['width'] = video_width
                video_info['height'] = video_height
                
                # æ ¹æ®è§†é¢‘åˆ†è¾¨ç‡è®¡ç®—åˆé€‚çš„å­—ä½“å¤§å°ï¼Œå¦‚æœæ²¡æœ‰æä¾›
                if not font_size:
                    # æ ¹æ®1080pè§†é¢‘20å·å­—ä½“ä¸ºåŸºå‡†è¿›è¡Œç­‰æ¯”ä¾‹è®¡ç®—ï¼Œç„¶åå‡å°20%
                    base_height = 1080
                    base_font_size = 16  # åŸæ¥20ï¼Œå‡å°20%åä¸º16
                    calculated_font_size = int(video_height / base_height * base_font_size)
                    # è®¾ç½®æœ€å°å’Œæœ€å¤§å­—ä½“å¤§å°é™åˆ¶ï¼Œè°ƒæ•´ä¸ºæ›´å°çš„å­—ä½“
                    font_size = max(18, min(32, calculated_font_size))  # æœ€å°18ï¼Œæœ€å¤§32
            
            # æ ¹æ®è§†é¢‘é«˜åº¦è°ƒæ•´å­—å¹•ä½ç½®
            margin_v = 30  # ä½¿ç”¨å›ºå®šåƒç´ å€¼ï¼Œè·ç¦»åº•éƒ¨30åƒç´ 
        except Exception as e:
            # é»˜è®¤å€¼
            font_size = font_size or 20
            margin_v = 60
        
        # ä½¿ç”¨assè¿‡æ»¤å™¨æ·»åŠ å­—å¹• (assæ ¼å¼æ¯”srtæœ‰æ›´å¥½çš„æ ¼å¼æ§åˆ¶)
        # å…ˆå°†SRTè½¬æ¢ä¸ºASSæ ¼å¼
        ass_path = subtitle_path.replace('.srt', '.ass')
        convert_cmd = f'ffmpeg -y -loglevel quiet -i "{subtitle_path}" "{ass_path}"'
        try:
            # æ‰§è¡ŒSRTåˆ°ASSçš„è½¬æ¢
            subprocess.run(convert_cmd, shell=True, check=True)
            
            # ä¿®æ”¹ASSæ–‡ä»¶ï¼Œè‡ªå®šä¹‰æ ·å¼
            if os.path.exists(ass_path):
                try:
                    # è¯»å–æ–‡ä»¶å†…å®¹
                    with open(ass_path, 'r', encoding='utf-8') as f:
                        ass_content = f.read()
                    
                    # ä½¿ç”¨æ›´ç²¾ç¡®çš„æ–¹å¼ä¿®æ”¹æ ·å¼
                    # æŸ¥æ‰¾æ ·å¼éƒ¨åˆ†çš„è¡Œ
                    lines = ass_content.split('\n')
                    new_lines = []
                    
                    # æ·»åŠ ä¸€ä¸ªæ ‡å¿—æ¥è·Ÿè¸ªæˆ‘ä»¬æ˜¯å¦å·²ä¿®æ”¹æ ·å¼éƒ¨åˆ†
                    modified_style = False
                    
                    # æ‰¾åˆ°[V4+ Styles]éƒ¨åˆ†å¹¶æ·»åŠ æˆ‘ä»¬çš„è‡ªå®šä¹‰æ ·å¼
                    in_style_section = False
                    
                    for i, line in enumerate(lines):
                        # æ£€æŸ¥æ˜¯å¦è¿›å…¥æ ·å¼éƒ¨åˆ†
                        if '[V4+ Styles]' in line:
                            in_style_section = True
                            new_lines.append(line)
                            continue
                            
                        # æ£€æŸ¥æ˜¯å¦ç¦»å¼€æ ·å¼éƒ¨åˆ†
                        if in_style_section and line.strip().startswith('['):
                            in_style_section = False
                            
                        # åœ¨æ ·å¼éƒ¨åˆ†ä¸­ï¼Œå¦‚æœè¿›å…¥äº†Formatè¡Œï¼ˆæ ·å¼å®šä¹‰è¡Œï¼‰
                        if in_style_section and line.strip().startswith('Format:'):
                            new_lines.append(line)
                            continue
                            
                        # å¦‚æœåœ¨æ ·å¼éƒ¨åˆ†ä¸­é‡åˆ°Style:è¡Œï¼Œæ›¿æ¢å®ƒ
                        if in_style_section and line.strip().startswith('Style:'):
                            # æå–æ ·å¼åç§°
                            style_name = line.split(',')[0].strip().replace('Style:', '').strip()
                            
                            # æ ¹æ®å‚æ•°è®¾ç½®èƒŒæ™¯æ¡†
                            if background_box:
                                # ASSé¢œè‰²æ ¼å¼æµ‹è¯•ï¼šç›´æ¥ä½¿ç”¨é€æ˜åº¦å€¼
                                # 0x00 = å®Œå…¨ä¸é€æ˜, 0xFF = å®Œå…¨é€æ˜
                                alpha_value = int(background_opacity * 255)  # ç›´æ¥ä½¿ç”¨é€æ˜åº¦
                                alpha_hex = format(alpha_value, '02X')
                                back_colour = f"&H{alpha_hex}000000"  # é€æ˜åº¦+é»‘è‰²èƒŒæ™¯
                                border_style = 4  # BorderStyle=4 (opaque box)
                                outline_width = 0  # å»æ‰æè¾¹ï¼Œåªä¿ç•™èƒŒæ™¯æ¡†
                                shadow_width = 0   # é˜´å½±å®½åº¦
                            else:
                                back_colour = f"&H000000FF"  # ä¸é€æ˜çº¢è‰²èƒŒæ™¯ï¼Œç”¨äºæµ‹è¯•
                                border_style = 1  # åªæœ‰æè¾¹ï¼Œæ— èƒŒæ™¯æ¡†
                                outline_width = 2  # æ­£å¸¸æè¾¹å®½åº¦
                                shadow_width = 0   # é˜´å½±å®½åº¦
                            
                            # åˆ›å»ºæ–°çš„æ ·å¼è¡Œï¼Œå®Œå…¨æ›¿æ¢åŸæœ‰æ ·å¼
                            # å¯¹é½å€¼ä½¿ç”¨2è¡¨ç¤ºåº•éƒ¨å¯¹é½ï¼ˆASSè§„èŒƒä¸­ï¼‰
                            # å¦‚æœæœ‰å­—ä½“æ–‡ä»¶è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨å®Œæ•´è·¯å¾„
                            font_for_ass = font_info if (isinstance(font_info, str) and os.path.exists(font_info) and font_info.endswith('.ttf')) else font_name
                            # ä¸­æ–‡å­—ä½“éœ€è¦åŠ ç²—
                            bold_value = 1 if language.lower() == 'chinese' else 0
                            new_style = f"Style: {style_name},{font_for_ass},{font_size},&H00FFFFFF,&H00000000,{outline_color},{back_colour},{bold_value},0,0,0,100,100,0,0,{border_style},{outline_width},{shadow_width},2,10,10,{margin_v}"
                            new_lines.append(new_style)
                            modified_style = True
                            continue
                        
                        # å¯¹äºå…¶ä»–è¡Œï¼Œä¿æŒä¸å˜
                        new_lines.append(line)
                    
                    # å¦‚æœæ²¡æœ‰ä¿®æ”¹ä»»ä½•æ ·å¼ï¼ˆå¼‚å¸¸æƒ…å†µï¼‰
                    if not modified_style:
                        # å°è¯•ç›´æ¥åœ¨å¤´éƒ¨æ·»åŠ å­—ä½“å®šä¹‰ä¿¡æ¯
                        if '[Script Info]' in ass_content:
                            # æ ¹æ®å‚æ•°è®¾ç½®èƒŒæ™¯æ¡†
                            if background_box:
                                alpha_hex = format(int(background_opacity * 255), '02X')
                                back_colour = f"&H{alpha_hex}000000"
                                border_style = 4
                                outline_width = 0  # å»æ‰æè¾¹ï¼Œåªä¿ç•™èƒŒæ™¯æ¡†
                                shadow_width = 0   # é˜´å½±å®½åº¦
                            else:
                                back_colour = f"&H000000FF"  # ä¸é€æ˜çº¢è‰²èƒŒæ™¯ï¼Œç”¨äºæµ‹è¯•
                                border_style = 1
                                outline_width = 2  # æ­£å¸¸æè¾¹å®½åº¦
                                shadow_width = 0   # é˜´å½±å®½åº¦
                            
                            # åœ¨Script Infoåæ·»åŠ å­—ä½“å£°æ˜
                            # å¦‚æœæœ‰å­—ä½“æ–‡ä»¶è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨å®Œæ•´è·¯å¾„
                            font_for_ass = font_info if (isinstance(font_info, str) and os.path.exists(font_info) and font_info.endswith('.ttf')) else font_name
                            # ä¸­æ–‡å­—ä½“éœ€è¦åŠ ç²—
                            bold_value = 1 if language.lower() == 'chinese' else 0
                            style_section = f"\n[V4+ Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\nStyle: Default,{font_for_ass},{font_size},&H00FFFFFF,&H00000000,{outline_color},{back_colour},{bold_value},0,0,0,100,100,0,0,{border_style},{outline_width},{shadow_width},2,10,10,{margin_v}\n"
                            ass_content = ass_content.replace('[Script Info]', f'[Script Info]{style_section}')
                    
                    # é‡æ–°ç»„åˆæ–‡ä»¶å†…å®¹
                    ass_content = '\n'.join(new_lines)
                    
                    # å†™å›æ–‡ä»¶
                    with open(ass_path, 'w', encoding='utf-8') as f: f.write(ass_content)
                except Exception as e: print(f"Failed to modify ASS file, will use original: {str(e)}")
        except: ass_path = subtitle_path
        
        # æ„å»ºffmpegå‘½ä»¤ï¼Œä½¿ç”¨å­—ä½“å’Œæ ·å¼è®¾ç½®ç¾åŒ–å­—å¹•
        # ä½¿ç”¨hwaccelå°è¯•å¯ç”¨GPUåŠ é€Ÿ
        if os.path.exists(ass_path) and ass_path.endswith('.ass'):
            # ä½¿ç”¨ASSå­—å¹•
            if font_dir:
                ffmpeg_cmd = f'ffmpeg -y -loglevel quiet -hwaccel auto -i "{input_video_path}" -vf "ass=\"{ass_path}\":fontsdir={font_dir}" -c:a copy "{output_video_path}"'
            else:
                ffmpeg_cmd = f'ffmpeg -y -loglevel quiet -hwaccel auto -i "{input_video_path}" -vf "ass=\"{ass_path}\"" -c:a copy "{output_video_path}"'
        else:
            # å›é€€åˆ°SRTå­—å¹•ï¼ŒæŒ‡å®šå­—ä½“å¤§å°å’Œä½ç½®
            # Alignment=2è¡¨ç¤ºåº•éƒ¨å¯¹é½ï¼ˆASSè§„èŒƒä¸­ï¼‰
            if font_dir:
                ffmpeg_cmd = f'ffmpeg -y -loglevel quiet -hwaccel auto -i "{input_video_path}" -vf "subtitles=\"{subtitle_path}\":force_style=\'FontSize={font_size},FontName={font_name},MarginV={margin_v},PrimaryColour=&H00FFFFFF,OutlineColour={outline_color},BackColour=&H80000000,Bold=1,Italic=0,Alignment=2,MarginL=10,MarginR=10\':fontsdir={font_dir}" -c:v libx264 -preset medium -crf 23 -c:a copy "{output_video_path}"'
            else:
                ffmpeg_cmd = f'ffmpeg -y -loglevel quiet -hwaccel auto -i "{input_video_path}" -vf "subtitles=\"{subtitle_path}\":force_style=\'FontSize={font_size},FontName={font_name},MarginV={margin_v},PrimaryColour=&H00FFFFFF,OutlineColour={outline_color},BackColour=&H80000000,Bold=1,Italic=0,Alignment=2,MarginL=10,MarginR=10\'" -c:v libx264 -preset medium -crf 23 -c:a copy "{output_video_path}"'
        
        # æ‰§è¡Œå‘½ä»¤
        subprocess.run(ffmpeg_cmd, shell=True, check=True)
        
        # éªŒè¯è¾“å‡ºæ–‡ä»¶
        if os.path.exists(output_video_path) and os.path.getsize(output_video_path) > 0: return True
        else: return False
            
    except Exception as e: return False




def add_subtitles_to_video_portrait(input_video_path: str, subtitle_path: str, output_video_path: str = None, font_size: int = None, outline_color: str = "&H00000000", background_box: bool = True, background_opacity: float = 0.5, language = 'english', force_redo = False) -> bool:
    try:
        if not os.path.exists(input_video_path): return False
        if not os.path.exists(subtitle_path): return False
        if os.path.isfile(output_video_path):
            if not force_redo: return False
            else: os.remove(output_video_path)
        # è·å–å­—ä½“ä¿¡æ¯
        font_info = get_local_font(language)
        font_dir = ""
        font_name = font_info
        
        # å¦‚æœè¿”å›çš„æ˜¯æ–‡ä»¶è·¯å¾„ï¼Œæå–å­—ä½“ç›®å½•å’Œå­—ä½“åç§°
        if isinstance(font_info, str) and os.path.exists(font_info) and font_info.endswith('.ttf'):
            font_dir = os.path.dirname(font_info)
            font_name = os.path.basename(font_info).replace('.ttf', '')
        elif isinstance(font_info, str) and '/' not in font_info:
            # å¦‚æœæ˜¯å­—ä½“åç§°ï¼ˆå¦‚ "Ubuntu"ï¼‰ï¼Œç›´æ¥ä½¿ç”¨
            font_name = font_info
        print(f"Testing with font: {font_name}, font_dir: {font_dir}")
        
        # è·å–è§†é¢‘ä¿¡æ¯
        video_info = {}
        try:
            cmd = f'ffprobe -v error -select_streams v:0 -show_entries stream=width,height -of csv=p=0:s=x "{input_video_path}"'
            result = subprocess.check_output(cmd, shell=True).decode('utf-8').strip()
            if result and 'x' in result:
                video_width, video_height = map(int, result.split('x'))
                video_info['width'] = video_width
                video_info['height'] = video_height
                print(f"Video dimensions: {video_width}x{video_height}")
                
                # æ£€æµ‹è§†é¢‘æ˜¯å¦ä¸ºç«–å±ï¼ˆå®½é«˜æ¯”å°äº1è¡¨ç¤ºç«–å±ï¼‰
                is_portrait = video_width / video_height < 1
                print(f"Video orientation: {'Portrait (9:16)' if is_portrait else 'Landscape'} ({video_width}x{video_height})")
                
                # æ ¹æ®è§†é¢‘åˆ†è¾¨ç‡è®¡ç®—åˆé€‚çš„å­—ä½“å¤§å°ï¼Œå¦‚æœæ²¡æœ‰æä¾›
                # å­—ä½“å¤§å°è®¡ç®— - æ ¹æ®è§†é¢‘é«˜åº¦ç¼©æ”¾
                if not font_size:
                    base_height = 1080
                    # å¯¹äºç«–å±ï¼Œå­—ä½“å¤§å°è°ƒæ•´ä¸ºé€‚åˆçš„å€¼ï¼Œæ¢å¤åŸæ¥çš„å¤§å°
                    if is_portrait:
                        base_font_size = 33  # æ¢å¤åŸæ¥çš„33
                        min_font = 22  # ä»27è°ƒæ•´ä¸º22ï¼Œé€‚åº”æ¨ªå±çš„è°ƒæ•´
                        max_font = 39  # æ¢å¤åŸæ¥çš„39
                    else:
                        base_font_size = 30  # æ¢å¤åŸæ¥çš„30
                        min_font = 24  # æ¢å¤åŸæ¥çš„24
                        max_font = 48  # æ¢å¤åŸæ¥çš„48
                    
                    calculated_font_size = int(video_height / base_height * base_font_size)
                    font_size = max(min_font, min(max_font, calculated_font_size))
                    print(f"Calculated font size for subtitles: {font_size} (for {'portrait' if is_portrait else 'landscape'} video)")
                else:
                    print(f"Using provided font size for subtitles: {font_size}")
                
                # æ ¹æ®è§†é¢‘æ–¹å‘è°ƒæ•´å­—å¹•ä½ç½® - æ”¾åœ¨åº•éƒ¨25%ä½ç½®
                if is_portrait:
                    # ç«–å±è§†é¢‘ä½¿ç”¨æ›´åˆé€‚çš„åº•éƒ¨è¾¹è·ï¼Œå¯¹åº”äºè§†é¢‘25%é«˜åº¦çš„ä½ç½®
                    margin_v = int(video_height * 0.25)  # è§†é¢‘é«˜åº¦çš„25%
                    margin_v = max(100, min(350, margin_v))  # ä¿è¯è¾¹è·åœ¨åˆç†èŒƒå›´å†…
                else:
                    margin_v = 60  # æ¨ªå±ä½¿ç”¨è¾ƒå°çš„å›ºå®šè¾¹è·
                print(f"Using margin_v: {margin_v} for {'portrait' if is_portrait else 'landscape'} video - positioned at bottom 25%")
            
                # è®¾ç½®æè¾¹å®½åº¦
                outline_width = 3.0 if is_portrait else 2.0
                print(f"Using outline width: {outline_width} for {'portrait' if is_portrait else 'landscape'} video")
            
        except Exception as e:
            print(f"Failed to get video info: {str(e)}")
            # é»˜è®¤å€¼ï¼Œé’ˆå¯¹ç«–å±è®¾ç½®æ›´å°çš„é»˜è®¤å€¼ï¼Œä¹Ÿå‡å°20%
            font_size = font_size or 16  # åŸæ¥20ï¼Œå‡å°20%åä¸º16
            margin_v = 80
            outline_width = 2.5
        
        # ä½¿ç”¨assè¿‡æ»¤å™¨æ·»åŠ å­—å¹• (assæ ¼å¼æ¯”srtæœ‰æ›´å¥½çš„æ ¼å¼æ§åˆ¶)
        # å…ˆå°†SRTè½¬æ¢ä¸ºASSæ ¼å¼
        ass_path = subtitle_path.replace('.srt', '.ass')
        if ass_path == subtitle_path:  # å¦‚æœæ–‡ä»¶å·²ç»æ˜¯.assåç¼€ï¼Œé¿å…è¦†ç›–
            ass_path = subtitle_path + '.ass'
            
        # å…ˆåˆ é™¤ç°æœ‰çš„ASSæ–‡ä»¶ï¼Œç¡®ä¿æ¯æ¬¡ç”Ÿæˆæ–°çš„
        if os.path.exists(ass_path):
            os.remove(ass_path)
            print(f"Removed existing ASS file: {ass_path}")
            
        # è½¬æ¢SRTä¸ºASSåŸºç¡€æ–‡ä»¶
        convert_cmd = f'ffmpeg -y -loglevel quiet -i "{subtitle_path}" "{ass_path}"'
        subprocess.run(convert_cmd, shell=True, check=True)
        
        # è¯»å–ASSå†…å®¹
        with open(ass_path, 'r', encoding='utf-8') as f:
            ass_content = f.read()
        
        # æ·»åŠ è‡ªåŠ¨æ¢è¡Œè®¾ç½®åˆ°Script Infoéƒ¨åˆ†
        play_res_x = int(video_width * 0.9)  # è®¾ç½®ä¸ºè§†é¢‘å®½åº¦çš„90%ï¼Œç¢°åˆ°è¾¹ç¼˜è‡ªåŠ¨æ¢è¡Œ
        
        # åˆ›å»ºæ–°çš„Script Infoéƒ¨åˆ†ï¼ŒåŒ…å«è‡ªåŠ¨æ¢è¡Œè®¾ç½®
        new_script_info = """[Script Info]\nScriptType: v4.00+\nWrapStyle: 2\nPlayResX: {}\nPlayResY: {}\nScaledBorderAndShadow: yes\n\n""".format(play_res_x, video_height)
        
        # æ‰¾åˆ°å¹¶æ›¿æ¢[Script Info]éƒ¨åˆ†
        if '[Script Info]' in ass_content:
            import re
            ass_content = re.sub(r'\[Script Info\][^\[]*', new_script_info, ass_content)
        
        # æ ¹æ®å‚æ•°è®¾ç½®èƒŒæ™¯æ¡†
        if background_box:
            # ASSé¢œè‰²æ ¼å¼ï¼šç›´æ¥ä½¿ç”¨é€æ˜åº¦å€¼
            alpha_value = int(background_opacity * 255)  # ç›´æ¥ä½¿ç”¨é€æ˜åº¦
            alpha_hex = format(alpha_value, '02X')
            back_colour = f"&H{alpha_hex}000000"  # é€æ˜åº¦+é»‘è‰²èƒŒæ™¯
            border_style = 4  # BorderStyle=4 (opaque box)
            outline_width_final = 0  # å»æ‰æè¾¹ï¼Œåªä¿ç•™èƒŒæ™¯æ¡†
            shadow_width = 0   # é˜´å½±å®½åº¦
            print(f"Portrait background opacity: {background_opacity}, alpha_value: {alpha_value}, alpha_hex: {alpha_hex}")
        else:
            back_colour = "&H80000000"  # é»˜è®¤èƒŒæ™¯è‰²
            border_style = 1  # åªæœ‰æè¾¹ï¼Œæ— èƒŒæ™¯æ¡†
            outline_width_final = outline_width  # ä½¿ç”¨åŸæ¥çš„æè¾¹å®½åº¦
            shadow_width = 1   # é˜´å½±å®½åº¦
        
        # åˆ›å»ºè‡ªå®šä¹‰æ ·å¼
        # å¦‚æœæœ‰å­—ä½“æ–‡ä»¶è·¯å¾„ï¼Œç›´æ¥ä½¿ç”¨å®Œæ•´è·¯å¾„
        font_for_ass = font_info if (isinstance(font_info, str) and os.path.exists(font_info) and font_info.endswith('.ttf')) else font_name
        custom_style = f"Style: Default,{font_for_ass},{font_size},&H00FFFFFF,&H00000000,{outline_color},{back_colour},1,0,0,0,100,100,0,0,{border_style},{outline_width_final},{shadow_width},2,10,10,{margin_v}"
        
        # æ›¿æ¢æ ·å¼éƒ¨åˆ†
        if '[V4+ Styles]' in ass_content:
            # å¦‚æœæœ‰æ ·å¼éƒ¨åˆ†ï¼Œæ‰¾åˆ°Style:è¡Œå¹¶æ›¿æ¢
            style_pattern = r'Style: [^\n]*'
            if re.search(style_pattern, ass_content):
                ass_content = re.sub(style_pattern, custom_style, ass_content)
            else:
                # å¦‚æœæ²¡æœ‰Styleè¡Œä½†æœ‰æ ·å¼éƒ¨åˆ†ï¼Œæ·»åŠ æˆ‘ä»¬çš„æ ·å¼
                format_line = ass_content.find('Format:', ass_content.find('[V4+ Styles]'))
                if format_line > 0:
                    insert_pos = ass_content.find('\n', format_line) + 1
                    ass_content = ass_content[:insert_pos] + custom_style + '\n' + ass_content[insert_pos:]
        else:
            # å¦‚æœæ²¡æœ‰æ ·å¼éƒ¨åˆ†ï¼Œæ·»åŠ å®Œæ•´çš„æ ·å¼éƒ¨åˆ†
            style_section = f"[V4+ Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\n{custom_style}\n\n"
            events_pos = ass_content.find('[Events]')
            if events_pos > 0:
                ass_content = ass_content[:events_pos] + style_section + ass_content[events_pos:]
            else:
                ass_content += '\n' + style_section
        
        # å†™å›æ›´æ–°çš„ASSæ–‡ä»¶
        with open(ass_path, 'w', encoding='utf-8') as f:
            f.write(ass_content)
        print(f"Created custom ASS file with auto line-wrap (PlayResX: {play_res_x}) and positioned at bottom 25% (margin_v={margin_v})")
        
        
        # æ„å»ºffmpegå‘½ä»¤ï¼Œä½¿ç”¨å­—ä½“å’Œæ ·å¼è®¾ç½®ç¾åŒ–å­—å¹•
        # ä½¿ç”¨hwaccelå°è¯•å¯ç”¨GPUåŠ é€Ÿ
        if os.path.exists(ass_path) and ass_path.endswith('.ass'):
            # ä½¿ç”¨ASSå­—å¹•
            if font_dir:
                ffmpeg_cmd = f'ffmpeg -y -loglevel quiet -hwaccel auto -i "{input_video_path}" -vf "ass=\"{ass_path}\":fontsdir={font_dir}" -c:a copy "{output_video_path}"'
            else:
                ffmpeg_cmd = f'ffmpeg -y -loglevel quiet -hwaccel auto -i "{input_video_path}" -vf "ass=\"{ass_path}\"" -c:a copy "{output_video_path}"'
        else:
            # å›é€€åˆ°SRTå­—å¹•ï¼ŒæŒ‡å®šå­—ä½“å¤§å°å’Œä½ç½®ï¼Œå¹¶å¢å¼ºæè¾¹ä»¥æé«˜å¯è¯»æ€§
            if font_dir:
                ffmpeg_cmd = f'ffmpeg -y -loglevel quiet -hwaccel auto -i "{input_video_path}" -vf "subtitles=\"{subtitle_path}\":force_style=\'FontSize={font_size},FontName={font_name},MarginV={margin_v},PrimaryColour=&H00FFFFFF,OutlineColour={outline_color},BackColour=&H80000000,Bold=1,Italic=0,Alignment=2,MarginL=10,MarginR=10,Outline=3\':fontsdir={font_dir}" -c:v libx264 -preset medium -crf 23 -c:a copy "{output_video_path}"'
            else:
                ffmpeg_cmd = f'ffmpeg -y -loglevel quiet -hwaccel auto -i "{input_video_path}" -vf "subtitles=\"{subtitle_path}\":force_style=\'FontSize={font_size},FontName={font_name},MarginV={margin_v},PrimaryColour=&H00FFFFFF,OutlineColour={outline_color},BackColour=&H80000000,Bold=1,Italic=0,Alignment=2,MarginL=10,MarginR=10,Outline=3\'" -c:v libx264 -preset medium -crf 23 -c:a copy "{output_video_path}"'
        
        # æ‰§è¡Œå‘½ä»¤
        subprocess.run(ffmpeg_cmd, shell=True, check=True)
        
        # éªŒè¯è¾“å‡ºæ–‡ä»¶
        if os.path.exists(output_video_path) and os.path.getsize(output_video_path) > 0:
            print(f"Successfully added subtitles to video: {output_video_path}")
            return True
        else:
            print(f"Failed to add subtitles: output file does not exist or is empty")
            return False
            
    except Exception as e:
        print(f"Error adding subtitles to video: {str(e)}")
        return False




def create_video_with_subtitles_onestep(
    input_image: str,
    input_audio: str,
    subtitle_path: str,
    output_video: str,
    font_size: Optional[int] = None,
    outline_color: str = "&H00000000",
    background_box: bool = True,
    background_opacity: float = 0.5,
    language: str = 'english',
    is_portrait: bool = False,
    effects: Optional[List[str]] = None,
    watermark_path: Optional[str] = None,
    progress_callback=None
) -> bool:
    """
    ä¸€æ­¥å®Œæˆå›¾ç‰‡+éŸ³é¢‘+å­—å¹•çš„è§†é¢‘ç”Ÿæˆ
    
    å‚æ•°:
        input_image: è¾“å…¥å›¾ç‰‡è·¯å¾„
        input_audio: è¾“å…¥éŸ³é¢‘è·¯å¾„
        subtitle_path: å­—å¹•æ–‡ä»¶è·¯å¾„ (SRTæ ¼å¼)
        output_video: è¾“å‡ºè§†é¢‘è·¯å¾„
        font_size: å­—ä½“å¤§å° (å¯é€‰ï¼Œä¸æä¾›åˆ™è‡ªåŠ¨è®¡ç®—)
        outline_color: æè¾¹é¢œè‰²
        background_box: æ˜¯å¦æ˜¾ç¤ºèƒŒæ™¯æ¡†
        background_opacity: èƒŒæ™¯æ¡†é€æ˜åº¦
        language: è¯­è¨€ (english/chinese)
        is_portrait: æ˜¯å¦ä¸ºç«–å±è§†é¢‘
        effects: ç‰¹æ•ˆåˆ—è¡¨ (ä¿ç•™å‚æ•°ï¼Œæš‚ä¸å®ç°)
        watermark_path: æ°´å°å›¾ç‰‡è·¯å¾„
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
    
    è¿”å›:
        bool: æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
    """
    
    try:
        if progress_callback:
            progress_callback("Starting one-step video creation with subtitles...")
        
        # éªŒè¯è¾“å…¥æ–‡ä»¶
        if not os.path.exists(input_image):
            if progress_callback:
                progress_callback(f"Error: Image file not found: {input_image}")
            return False
            
        if not os.path.exists(input_audio):
            if progress_callback:
                progress_callback(f"Error: Audio file not found: {input_audio}")
            return False
            
        # æ£€æŸ¥å­—å¹•æ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦å­—å¹•ï¼‰
        has_subtitles = subtitle_path is not None and os.path.exists(subtitle_path)
        if subtitle_path is not None and not has_subtitles:
            if progress_callback:
                progress_callback(f"Error: Subtitle file not found: {subtitle_path}")
            return False
        
        # è·å–å­—ä½“ä¿¡æ¯
        font_info = get_local_font(language)
        font_dir = ""
        font_name = font_info
        
        if isinstance(font_info, str) and os.path.exists(font_info) and font_info.endswith('.ttf'):
            font_dir = os.path.dirname(font_info)
            font_name = os.path.basename(font_info).replace('.ttf', '')
        elif isinstance(font_info, str) and '/' not in font_info:
            font_name = font_info
        
        # è·å–è§†é¢‘åˆ†è¾¨ç‡ï¼ˆä»å›¾ç‰‡ï¼‰
        probe_cmd = f'ffprobe -v error -select_streams v:0 -show_entries stream=width,height -of csv=p=0:s=x "{input_image}"'
        result = subprocess.check_output(probe_cmd, shell=True).decode('utf-8').strip()
        
        if result and 'x' in result:
            video_width, video_height = map(int, result.split('x'))
        else:
            # é»˜è®¤åˆ†è¾¨ç‡
            video_width = 1920 if not is_portrait else 1080
            video_height = 1080 if not is_portrait else 1920
        
        if progress_callback:
            progress_callback(f"Video dimensions: {video_width}x{video_height}")
        
        # è®¡ç®—å­—ä½“å¤§å°ï¼ˆå¦‚æœæœªæä¾›ï¼‰
        if not font_size:
            base_height = 1080
            if is_portrait:
                # ç«–å±è§†é¢‘çš„å­—ä½“è®¡ç®—
                if language.lower() == 'chinese':
                    base_font_size = 21  # ä¸­æ–‡ç«–å±åŸºç¡€å­—ä½“
                    min_font = 18
                    max_font = 39
                else:
                    base_font_size = 30  # è‹±æ–‡ç«–å±åŸºç¡€å­—ä½“
                    min_font = 24
                    max_font = 48
            else:
                # æ¨ªå±è§†é¢‘çš„å­—ä½“è®¡ç®—
                base_font_size = 16  # å‡å°20%åçš„åŸºç¡€å­—ä½“
                min_font = 18
                max_font = 32
            
            calculated_font_size = int(video_height / base_height * base_font_size)
            font_size = max(min_font, min(max_font, calculated_font_size))
        
        # è®¡ç®—å­—å¹•è¾¹è·
        if is_portrait:
            margin_v = int(video_height * 0.25)  # ç«–å±ï¼šåº•éƒ¨25%ä½ç½®
            margin_v = max(100, min(350, margin_v))
        else:
            margin_v = 30  # æ¨ªå±ï¼šå›ºå®š30åƒç´ 
        
        # è®¾ç½®æè¾¹å®½åº¦
        outline_width = 3.0 if is_portrait else 2.0
        
        # æ£€æµ‹GPUç¼–ç å™¨
        use_gpu_encoding = False
        gpu_encoder = 'libx264'
        
        # åœ¨RunPodç¯å¢ƒæ£€æµ‹GPU
        if os.environ.get('RUNPOD_POD_ID') or which_ubuntu == 'RunPod':
            test_cmd = ['ffmpeg', '-hide_banner', '-f', 'lavfi', '-i', 'nullsrc=s=256x256:d=0.1', 
                       '-c:v', 'h264_nvenc', '-f', 'null', '-']
            try:
                test_result = subprocess.run(test_cmd, capture_output=True, text=True)
                if test_result.returncode == 0:
                    use_gpu_encoding = True
                    gpu_encoder = 'h264_nvenc'
                    if progress_callback:
                        progress_callback("âœ… GPU encoder available - will use h264_nvenc")
            except:
                pass
        
        # æ„å»ºFFmpegå‘½ä»¤
        cmd = [
            'ffmpeg', '-y', '-loglevel', 'error',
            '-loop', '1', '-i', input_image,  # å›¾ç‰‡è¾“å…¥
            '-i', input_audio,                # éŸ³é¢‘è¾“å…¥
        ]
        
        # æ·»åŠ è§†é¢‘æ»¤é•œ
        video_filters = []
        
        # ç¼©æ”¾åˆ°ç›®æ ‡åˆ†è¾¨ç‡
        video_filters.append(f"scale={video_width}:{video_height}:force_original_aspect_ratio=decrease")
        video_filters.append(f"pad={video_width}:{video_height}:(ow-iw)/2:(oh-ih)/2")
        video_filters.append("setsar=1")
        
        # åªæœ‰åœ¨æœ‰å­—å¹•æ–‡ä»¶æ—¶æ‰æ·»åŠ å­—å¹•æ»¤é•œ
        if has_subtitles:
            # æ ¹æ®èƒŒæ™¯æ¡†è®¾ç½®æ ·å¼
            if background_box:
                alpha_value = int(background_opacity * 255)
                alpha_hex = format(alpha_value, '02X')
                # ASSæ ¼å¼ï¼šBorderStyle=4è¡¨ç¤ºèƒŒæ™¯æ¡†ï¼ŒOutline=0å»æ‰æè¾¹
                border_style = "BorderStyle=4,Outline=0"
                back_colour = f"BackColour=&H{alpha_hex}000000"
            else:
                # BorderStyle=1è¡¨ç¤ºåªæœ‰æè¾¹
                border_style = f"BorderStyle=1,Outline={outline_width}"
                back_colour = "BackColour=&H80000000"
            
            # ä¸­æ–‡éœ€è¦åŠ ç²—
            bold_value = 1 if language.lower() == 'chinese' else 0
            
            # æ„å»ºå­—å¹•æ ·å¼å­—ç¬¦ä¸²
            subtitle_style = (
                f"FontName={font_name},"
                f"FontSize={font_size},"
                f"PrimaryColour=&H00FFFFFF,"
                f"OutlineColour={outline_color},"
                f"{back_colour},"
                f"Bold={bold_value},"
                f"{border_style},"
                f"Alignment=2,"  # åº•éƒ¨å±…ä¸­
                f"MarginV={margin_v}"
            )
            
            # å¦‚æœæœ‰å­—ä½“ç›®å½•ï¼Œæ·»åŠ fontsdirå‚æ•°
            if font_dir:
                subtitle_filter = f"subtitles='{subtitle_path}':force_style='{subtitle_style}':fontsdir='{font_dir}'"
            else:
                subtitle_filter = f"subtitles='{subtitle_path}':force_style='{subtitle_style}'"
            
            # æ·»åŠ å­—å¹•æ»¤é•œ
            video_filters.append(subtitle_filter)
        
        # å¤„ç†æ»¤é•œç»„åˆ
        if watermark_path and os.path.exists(watermark_path):
            # æœ‰æ°´å°çš„æƒ…å†µï¼Œä½¿ç”¨ -filter_complex
            watermark_width = int(video_width / 8)  # æ°´å°å®½åº¦ä¸ºè§†é¢‘å®½åº¦çš„ 1/8
            
            if video_filters:
                # æœ‰å­—å¹•å’Œæ°´å°
                video_filters_str = ",".join(video_filters)
                # ä½¿ç”¨ filter_complex ç»„åˆå­—å¹•å’Œæ°´å°
                filter_complex = f"[0:v]{video_filters_str}[v];movie={watermark_path},scale={watermark_width}:-1[watermark];[v][watermark]overlay=10:10"
                cmd.extend([
                    '-filter_complex', filter_complex,
                ])
            else:
                # åªæœ‰æ°´å°ï¼Œæ²¡æœ‰å­—å¹•
                filter_complex = f"movie={watermark_path},scale={watermark_width}:-1[watermark];[0:v][watermark]overlay=10:10"
                cmd.extend([
                    '-filter_complex', filter_complex,
                ])
            
            if progress_callback:
                progress_callback(f"Adding watermark from: {watermark_path}")
        else:
            # æ²¡æœ‰æ°´å°çš„æƒ…å†µ
            if video_filters:
                # åªæœ‰å­—å¹•ï¼Œä½¿ç”¨ -vf
                video_filters_str = ",".join(video_filters)
                cmd.extend([
                    '-vf', video_filters_str,
                ])
        
        cmd.extend([
            '-c:v', gpu_encoder,              # è§†é¢‘ç¼–ç å™¨
        ])
        
        # GPUç¼–ç å‚æ•°
        if use_gpu_encoding:
            cmd.extend([
                '-preset', 'p4',              # NVENCé¢„è®¾
                '-cq:v', '19',                # è´¨é‡å› å­
            ])
        else:
            cmd.extend([
                '-preset', 'medium',
                '-crf', '23',
            ])
        
        # éŸ³é¢‘å‚æ•° - ç¡®ä¿48kHzè¾“å‡º
        cmd.extend([
            '-c:a', 'aac',                    # éŸ³é¢‘ç¼–ç å™¨
            '-af', 'aresample=48000',         # éŸ³é¢‘é‡é‡‡æ ·æ»¤é•œ
            '-ar', '48000',                   # 48kHzé‡‡æ ·ç‡
            '-ac', '2',                       # ç«‹ä½“å£°
            '-b:a', '128k',                   # éŸ³é¢‘æ¯”ç‰¹ç‡
            '-pix_fmt', 'yuv420p',            # åƒç´ æ ¼å¼
            '-r', '30',                       # å¸§ç‡
            '-shortest',                      # ä»¥æœ€çŸ­æµä¸ºå‡†
            '-vsync', 'cfr',                  # å›ºå®šå¸§ç‡
            '-movflags', '+faststart',        # ä¼˜åŒ–æµåª’ä½“æ’­æ”¾
            output_video
        ])
        
        if progress_callback:
            progress_callback(f"Executing FFmpeg command with {gpu_encoder} encoder...")
        
        # æ‰§è¡Œå‘½ä»¤
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            if progress_callback:
                progress_callback(f"FFmpeg error: {result.stderr}")
            return False
        
        # éªŒè¯è¾“å‡ºæ–‡ä»¶
        if os.path.exists(output_video) and os.path.getsize(output_video) > 0:
            if progress_callback:
                progress_callback(f"âœ… Video created successfully: {output_video}")
            return True
        else:
            if progress_callback:
                progress_callback("Error: Output file not created or empty")
            return False
            
    except Exception as e:
        if progress_callback:
            progress_callback(f"Exception: {str(e)}")
        return False
